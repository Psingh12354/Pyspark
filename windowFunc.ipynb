{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ae66a7b-f8d3-448c-ab62-2fc4b773e8e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Window Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a4b13f7-106f-4e44-8b12-33dad6e0cc0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß† PySpark Window Functions Explained\n",
    "\n",
    "Window functions in PySpark allow you to perform calculations **across a set of rows related to the current row**, without collapsing them into a single result (unlike aggregate functions).\n",
    "\n",
    "---\n",
    "\n",
    "## üîç What Is a Window?\n",
    "\n",
    "A **window** defines a **subset of rows** within a DataFrame over which a window function operates.\n",
    "\n",
    "A window is defined using:\n",
    "\n",
    "```\n",
    "Window.partitionBy(...).orderBy(...)\n",
    "```\n",
    "\n",
    "- `partitionBy(...)`: (Optional) Groups data into partitions ‚Äî like SQL's `GROUP BY`. Ranking and calculations reset for each partition.\n",
    "- `orderBy(...)`: (Required for ranking functions) Orders rows within each partition ‚Äî critical for assigning rank, lag/lead, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú Common PySpark Window Functions\n",
    "\n",
    "### 1. `row_number()`\n",
    "\n",
    "- Assigns a unique sequential number to each row **within a partition**, ordered by the specified column.\n",
    "- **No ties** ‚Äî even rows with same values get different numbers.\n",
    "\n",
    "```\n",
    "row_number().over(Window.partitionBy(\"Department\").orderBy(\"Salary\"))\n",
    "```\n",
    "\n",
    "| Employee | Salary | row_number |\n",
    "|----------|--------|------------|\n",
    "| Alice    | 5000   | 1          |\n",
    "| Bob      | 4800   | 2          |\n",
    "| Charlie  | 4800   | 3          |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `rank()`\n",
    "\n",
    "- Assigns ranks **with gaps** in case of ties.\n",
    "- If two rows are tied at rank 2, the next rank will be 4 (not 3).\n",
    "\n",
    "```\n",
    "rank().over(Window.partitionBy(\"Department\").orderBy(\"Salary\"))\n",
    "```\n",
    "\n",
    "| Employee | Salary | rank |\n",
    "|----------|--------|------|\n",
    "| Alice    | 5000   | 1    |\n",
    "| Bob      | 4800   | 2    |\n",
    "| Charlie  | 4800   | 2    |\n",
    "| David    | 4700   | 4    |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `dense_rank()`\n",
    "\n",
    "- Similar to `rank()`, but **no gaps** in ranking.\n",
    "- Ties share the same rank, and the next rank is incremented by 1.\n",
    "\n",
    "```\n",
    "dense_rank().over(Window.partitionBy(\"Department\").orderBy(\"Salary\"))\n",
    "```\n",
    "\n",
    "| Employee | Salary | dense_rank |\n",
    "|----------|--------|------------|\n",
    "| Alice    | 5000   | 1          |\n",
    "| Bob      | 4800   | 2          |\n",
    "| Charlie  | 4800   | 2          |\n",
    "| David    | 4700   | 3          |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. `lag(column, offset)`\n",
    "\n",
    "- Retrieves the **value of a previous row** in the window.\n",
    "- Useful for comparing current and previous row (e.g., change in salary).\n",
    "\n",
    "```\n",
    "lag(\"Salary\", 1).over(Window.partitionBy(\"Department\").orderBy(\"Salary\"))\n",
    "```\n",
    "\n",
    "| Employee | Salary | lag_salary |\n",
    "|----------|--------|------------|\n",
    "| Alice    | 5000   | null       |\n",
    "| Bob      | 4800   | 5000       |\n",
    "| Charlie  | 4700   | 4800       |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. `lead(column, offset)`\n",
    "\n",
    "- Retrieves the **value of the next row** in the window.\n",
    "- Useful for forward-looking comparisons (e.g., predicting trends).\n",
    "\n",
    "```\n",
    "lead(\"Salary\", 1).over(Window.partitionBy(\"Department\").orderBy(\"Salary\"))\n",
    "```\n",
    "\n",
    "| Employee | Salary | lead_salary |\n",
    "|----------|--------|-------------|\n",
    "| Alice    | 5000   | 4800        |\n",
    "| Bob      | 4800   | 4700        |\n",
    "| Charlie  | 4700   | null        |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Full Window Spec Example\n",
    "\n",
    "```\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead\n",
    "\n",
    "windowSpec = Window.partitionBy(\"Department\").orderBy(\"Salary\")\n",
    "\n",
    "df.withColumn(\"row_number\", row_number().over(windowSpec)) \\\n",
    "  .withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "  .withColumn(\"dense_rank\", dense_rank().over(windowSpec)) \\\n",
    "  .withColumn(\"lag_salary\", lag(\"Salary\", 1).over(windowSpec)) \\\n",
    "  .withColumn(\"lead_salary\", lead(\"Salary\", 1).over(windowSpec)) \\\n",
    "  .show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary of Differences\n",
    "\n",
    "| Function      | Ties | Gaps in Ranks | Use Case                        |\n",
    "|---------------|------|----------------|---------------------------------|\n",
    "| `row_number()` | ‚ùå   | N/A            | Always unique row order         |\n",
    "| `rank()`       | ‚úÖ   | ‚úÖ             | Official ranking with gaps      |\n",
    "| `dense_rank()` | ‚úÖ   | ‚ùå             | Compact ranks without skipping  |\n",
    "| `lag()`        | N/A  | N/A            | Look back to previous value     |\n",
    "| `lead()`       | N/A  | N/A            | Look forward to next value      |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Bonus Tip: Without `partitionBy`\n",
    "\n",
    "If you omit `partitionBy`, window functions apply **across the entire DataFrame**.\n",
    "\n",
    "```\n",
    "Window.orderBy(\"Salary\")\n",
    "```\n",
    "\n",
    "This ranks rows globally (not grouped by department).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ddf851b-0f17-40b4-8467-aedb35db64cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+----------+----+----------+----------+-----------+\n|Department|Employee|Salary|row_number|rank|dense_rank|lag_salary|lead_salary|\n+----------+--------+------+----------+----+----------+----------+-----------+\n|        HR|   David|  4000|         1|   1|         1|      null|       4000|\n|        HR|     Eva|  4000|         2|   1|         1|      4000|       3900|\n|        HR|   Frank|  3900|         3|   3|         2|      4000|       null|\n|     Sales|   Alice|  5000|         1|   1|         1|      null|       4800|\n|     Sales|     Bob|  4800|         2|   2|         2|      5000|       4800|\n|     Sales| Charlie|  4800|         3|   2|         2|      4800|       null|\n+----------+--------+------+----------+----+----------+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"WindowFunctionsEnhanced\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Sales\", \"Alice\", 5000),\n",
    "    (\"Sales\", \"Bob\", 4800),\n",
    "    (\"Sales\", \"Charlie\", 4800),\n",
    "    (\"HR\", \"David\", 4000),\n",
    "    (\"HR\", \"Eva\", 4000),\n",
    "    (\"HR\", \"Frank\", 3900),\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"Department\", \"Employee\", \"Salary\"])\n",
    "\n",
    "# Define window specification: Partition by Department, Order by Salary descending\n",
    "windowSpec = Window.partitionBy(\"Department\").orderBy(df[\"Salary\"].desc())\n",
    "\n",
    "# Apply window functions\n",
    "df_with_all = df \\\n",
    "    .withColumn(\"row_number\", row_number().over(windowSpec)) \\\n",
    "    .withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "    .withColumn(\"dense_rank\", dense_rank().over(windowSpec)) \\\n",
    "    .withColumn(\"lag_salary\", lag(\"Salary\", 1).over(windowSpec)) \\\n",
    "    .withColumn(\"lead_salary\", lead(\"Salary\", 1).over(windowSpec))\n",
    "\n",
    "# Show result\n",
    "df_with_all.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf70bbb6-e7c3-4f1c-a91a-851dd5d2abcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-07-09 16:25:45",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}